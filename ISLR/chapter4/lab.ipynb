{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Logistic Regression, LDA, QDA, and KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Market Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>5.010</td>\n",
       "      <td>1.1913</td>\n",
       "      <td>0.959</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>-1.055</td>\n",
       "      <td>1.2965</td>\n",
       "      <td>1.032</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-2.624</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>1.2760</td>\n",
       "      <td>0.614</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.614</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.2057</td>\n",
       "      <td>0.213</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5  Volume  Today Direction\n",
       "0  2001  0.381 -0.192 -2.624 -1.055  5.010  1.1913  0.959        Up\n",
       "1  2001  0.959  0.381 -0.192 -2.624 -1.055  1.2965  1.032        Up\n",
       "2  2001  1.032  0.959  0.381 -0.192 -2.624  1.4112 -0.623      Down\n",
       "3  2001 -0.623  1.032  0.959  0.381 -0.192  1.2760  0.614        Up\n",
       "4  2001  0.614 -0.623  1.032  0.959  0.381  1.2057  0.213        Up"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smarket_df = pd.read_csv('../data/Smarket.csv')\n",
    "smarket_df.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "smarket_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2003.016000</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.00561</td>\n",
       "      <td>1.478305</td>\n",
       "      <td>0.003138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.409018</td>\n",
       "      <td>1.136299</td>\n",
       "      <td>1.136280</td>\n",
       "      <td>1.138703</td>\n",
       "      <td>1.138774</td>\n",
       "      <td>1.14755</td>\n",
       "      <td>0.360357</td>\n",
       "      <td>1.136334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2001.000000</td>\n",
       "      <td>-4.922000</td>\n",
       "      <td>-4.922000</td>\n",
       "      <td>-4.922000</td>\n",
       "      <td>-4.922000</td>\n",
       "      <td>-4.92200</td>\n",
       "      <td>0.356070</td>\n",
       "      <td>-4.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2002.000000</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.639500</td>\n",
       "      <td>-0.640000</td>\n",
       "      <td>-0.640000</td>\n",
       "      <td>-0.64000</td>\n",
       "      <td>1.257400</td>\n",
       "      <td>-0.639500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2003.000000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.03850</td>\n",
       "      <td>1.422950</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2004.000000</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.596750</td>\n",
       "      <td>0.59700</td>\n",
       "      <td>1.641675</td>\n",
       "      <td>0.596750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2005.000000</td>\n",
       "      <td>5.733000</td>\n",
       "      <td>5.733000</td>\n",
       "      <td>5.733000</td>\n",
       "      <td>5.733000</td>\n",
       "      <td>5.73300</td>\n",
       "      <td>3.152470</td>\n",
       "      <td>5.733000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Year         Lag1         Lag2         Lag3         Lag4  \\\n",
       "count  1250.000000  1250.000000  1250.000000  1250.000000  1250.000000   \n",
       "mean   2003.016000     0.003834     0.003919     0.001716     0.001636   \n",
       "std       1.409018     1.136299     1.136280     1.138703     1.138774   \n",
       "min    2001.000000    -4.922000    -4.922000    -4.922000    -4.922000   \n",
       "25%    2002.000000    -0.639500    -0.639500    -0.640000    -0.640000   \n",
       "50%    2003.000000     0.039000     0.039000     0.038500     0.038500   \n",
       "75%    2004.000000     0.596750     0.596750     0.596750     0.596750   \n",
       "max    2005.000000     5.733000     5.733000     5.733000     5.733000   \n",
       "\n",
       "             Lag5       Volume        Today  \n",
       "count  1250.00000  1250.000000  1250.000000  \n",
       "mean      0.00561     1.478305     0.003138  \n",
       "std       1.14755     0.360357     1.136334  \n",
       "min      -4.92200     0.356070    -4.922000  \n",
       "25%      -0.64000     1.257400    -0.639500  \n",
       "50%       0.03850     1.422950     0.038500  \n",
       "75%       0.59700     1.641675     0.596750  \n",
       "max       5.73300     3.152470     5.733000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smarket_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>0.033195</td>\n",
       "      <td>0.035689</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.539006</td>\n",
       "      <td>0.030095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag1</th>\n",
       "      <td>0.029700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026294</td>\n",
       "      <td>-0.010803</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.005675</td>\n",
       "      <td>0.040910</td>\n",
       "      <td>-0.026155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag2</th>\n",
       "      <td>0.030596</td>\n",
       "      <td>-0.026294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025897</td>\n",
       "      <td>-0.010854</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>-0.043383</td>\n",
       "      <td>-0.010250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag3</th>\n",
       "      <td>0.033195</td>\n",
       "      <td>-0.010803</td>\n",
       "      <td>-0.025897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024051</td>\n",
       "      <td>-0.018808</td>\n",
       "      <td>-0.041824</td>\n",
       "      <td>-0.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag4</th>\n",
       "      <td>0.035689</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.010854</td>\n",
       "      <td>-0.024051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027084</td>\n",
       "      <td>-0.048414</td>\n",
       "      <td>-0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lag5</th>\n",
       "      <td>0.029788</td>\n",
       "      <td>-0.005675</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>-0.018808</td>\n",
       "      <td>-0.027084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.022002</td>\n",
       "      <td>-0.034860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>0.539006</td>\n",
       "      <td>0.040910</td>\n",
       "      <td>-0.043383</td>\n",
       "      <td>-0.041824</td>\n",
       "      <td>-0.048414</td>\n",
       "      <td>-0.022002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Today</th>\n",
       "      <td>0.030095</td>\n",
       "      <td>-0.026155</td>\n",
       "      <td>-0.010250</td>\n",
       "      <td>-0.002448</td>\n",
       "      <td>-0.006900</td>\n",
       "      <td>-0.034860</td>\n",
       "      <td>0.014592</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Year      Lag1      Lag2      Lag3      Lag4      Lag5    Volume  \\\n",
       "Year    1.000000  0.029700  0.030596  0.033195  0.035689  0.029788  0.539006   \n",
       "Lag1    0.029700  1.000000 -0.026294 -0.010803 -0.002986 -0.005675  0.040910   \n",
       "Lag2    0.030596 -0.026294  1.000000 -0.025897 -0.010854 -0.003558 -0.043383   \n",
       "Lag3    0.033195 -0.010803 -0.025897  1.000000 -0.024051 -0.018808 -0.041824   \n",
       "Lag4    0.035689 -0.002986 -0.010854 -0.024051  1.000000 -0.027084 -0.048414   \n",
       "Lag5    0.029788 -0.005675 -0.003558 -0.018808 -0.027084  1.000000 -0.022002   \n",
       "Volume  0.539006  0.040910 -0.043383 -0.041824 -0.048414 -0.022002  1.000000   \n",
       "Today   0.030095 -0.026155 -0.010250 -0.002448 -0.006900 -0.034860  0.014592   \n",
       "\n",
       "           Today  \n",
       "Year    0.030095  \n",
       "Lag1   -0.026155  \n",
       "Lag2   -0.010250  \n",
       "Lag3   -0.002448  \n",
       "Lag4   -0.006900  \n",
       "Lag5   -0.034860  \n",
       "Volume  0.014592  \n",
       "Today   1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smarket_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP6+Qq26TUAj7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bd84160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.pointplot(x=\"Year\", y=\"Volume\", data=smarket_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercpet: [-0.11454962]\n",
      "Coefficients:\n",
      "\tLag1: -0.07279035244097605\n",
      "\tLag2: -0.042291015688171354\n",
      "\tLag3: 0.01095799639819893\n",
      "\tLag4: 0.00921799170450773\n",
      "\tLag5: 0.010230310971632023\n",
      "\tVolume: 0.12793930878661286\n",
      "p-values:\n",
      "\t Lag1: 0.16008618568035235\n",
      "\t Lag2: 0.39494704292074356\n",
      "\t Lag3: 0.8285459051313201\n",
      "\t Lag4: 0.8816470639628737\n",
      "\t Lag5: 0.8481132399931779\n",
      "\t Volume: 0.417518499939722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "X = smarket_df[['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']]\n",
    "y = np.ravel(smarket_df['Direction'])\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "# printing out intercept, coefficients and p-values\n",
    "names = ['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']\n",
    "f_statistics, p_values = f_classif(X, y)\n",
    "\n",
    "print(\"Intercpet: {}\".format(log_model.intercept_))\n",
    "print('Coefficients:')\n",
    "for i in range(0, len(features)):\n",
    "    print(\"\\t{}: {}\".format(names[i], log_model.coef_[0][i]))\n",
    "print('p-values:')\n",
    "for i in range(0, len(features)):\n",
    "    print(\"\\t {}: {}\".format(names[i], p_values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down       0.51      0.24      0.33       602\n",
      "         Up       0.53      0.79      0.63       648\n",
      "\n",
      "avg / total       0.52      0.52      0.48      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "prediction_probabilities = log_model.predict_proba(X)\n",
    "predicted_direction = list()\n",
    "for prediction in prediction_probabilities:\n",
    "    if prediction[0] > .5:\n",
    "        predicted_direction.append('Down')\n",
    "    else:\n",
    "        predicted_direction.append('Up')\n",
    "print(confusion_matrix(y, np.asarray(predicted_direction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Down       0.80      0.04      0.07       111\n",
      "         Up       0.57      0.99      0.72       141\n",
      "\n",
      "avg / total       0.67      0.57      0.43       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_model2 = LogisticRegression()\n",
    "\n",
    "train_X = smarket_df[smarket_df.Year < 2005][['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']]\n",
    "train_y = np.ravel(smarket_df[smarket_df.Year < 2005]['Direction'])\n",
    "test_X = smarket_df[smarket_df.Year == 2005][['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']]\n",
    "test_y = np.ravel(smarket_df[smarket_df.Year == 2005]['Direction'])\n",
    "\n",
    "log_model2.fit(train_X, train_y)\n",
    "\n",
    "prediction_probabilities = log_model.predict_proba(test_X)\n",
    "predicted_direction = list()\n",
    "for prediction in prediction_probabilities:\n",
    "    if prediction[0] > .5:\n",
    "        predicted_direction.append('Down')\n",
    "    else:\n",
    "        predicted_direction.append('Up')\n",
    "print(classification_report(test_y, np.asarray(predicted_direction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.559523809524\n"
     ]
    }
   ],
   "source": [
    "log_model3 = LogisticRegression()\n",
    "\n",
    "train_X = smarket_df[smarket_df.Year < 2005][['Lag1', 'Lag2']]\n",
    "train_y = np.ravel(smarket_df[smarket_df.Year < 2005]['Direction'])\n",
    "test_X = smarket_df[smarket_df.Year == 2005][['Lag1', 'Lag2']]\n",
    "test_y = np.ravel(smarket_df[smarket_df.Year == 2005]['Direction'])\n",
    "\n",
    "log_model3.fit(train_X, train_y)\n",
    "\n",
    "prediction_probabilities = log_model3.predict_proba(test_X)\n",
    "predictions = log_model3.predict(test_X)\n",
    "predicted_direction = list()\n",
    "for prediction in prediction_probabilities:\n",
    "    if prediction[0] > .5:\n",
    "        predicted_direction.append('Down')\n",
    "    else:\n",
    "        predicted_direction.append('Up')\n",
    "print(accuracy_score(test_y, np.asarray(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probabilities of groups:\n",
      "\tDown:0.49198396793587174\n",
      "\tUp:0.5080160320641283\n",
      "Group means:\n",
      "\tDown, Lag1: 0.04279022403258651\n",
      "\tDown, Lag2: 0.0338940936863544\n",
      "\tUp, Lag1: -0.03954635108481257\n",
      "\tUp, Lag2: -0.031325443786982286\n",
      "Coefficients:\n",
      "\tLag1:-0.05544077817925726\n",
      "\tLag2:-0.044345199897942424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "features = ['Lag1', 'Lag2']\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "lda_model.fit(train_X, train_y)\n",
    "\n",
    "print('Prior Probabilities of groups:')\n",
    "for i in range(0, len(lda_model.classes_)):\n",
    "    print('\\t{}:{}'.format(lda_model.classes_[i], lda_model.priors_[i]))\n",
    "    \n",
    "print('Group means:')\n",
    "for i in range (0, len(lda_model.classes_)):\n",
    "    for j in range(0, len(features)):\n",
    "        print('\\t{}, {}: {}'.format(lda_model.classes_[i],\n",
    "                                     features[j],\n",
    "                                     lda_model.means_[i][j]))\n",
    "print('Coefficients:')\n",
    "for i in range(0, lda_model.coef_.shape[1]):\n",
    "    print('\\t{}:{}'.format(features[i], lda_model.coef_[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 35  35]\n",
      " [ 76 106]]\n",
      "0.559523809524\n"
     ]
    }
   ],
   "source": [
    "predictions = lda_model.predict(test_X)\n",
    "\n",
    "print(confusion_matrix(test_y, np.asarray(predictions)).transpose())\n",
    "print(accuracy_score(test_y, np.asarray(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probabilities of groups:\n",
      "\tDown:0.49198396793587174\n",
      "\tUp:0.5080160320641283\n",
      "Group means:\n",
      "\tDown, Lag1: 0.04279022403258651\n",
      "\tDown, Lag2: 0.0338940936863544\n",
      "\tUp, Lag1: -0.03954635108481257\n",
      "\tUp, Lag2: -0.031325443786982286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "qda_model = QuadraticDiscriminantAnalysis()\n",
    "qda_model.fit(train_X, train_y)\n",
    "\n",
    "print('Prior Probabilities of groups:')\n",
    "for i in range(0, len(qda_model.classes_)):\n",
    "    print('\\t{}:{}'.format(qda_model.classes_[i], qda_model.priors_[i]))\n",
    "    \n",
    "print('Group means:')\n",
    "for i in range (0, len(qda_model.classes_)):\n",
    "    for j in range(0, len(features)):\n",
    "        print('\\t{}, {}: {}'.format(qda_model.classes_[i],\n",
    "                                     features[j],\n",
    "                                     qda_model.means_[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30  20]\n",
      " [ 81 121]]\n",
      "0.599206349206\n"
     ]
    }
   ],
   "source": [
    "predictions = qda_model.predict(test_X)\n",
    "\n",
    "print(confusion_matrix(test_y, np.asarray(predictions)).transpose())\n",
    "print(accuracy_score(test_y, np.asarray(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43 58]\n",
      " [68 83]]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classif = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_classif.fit(train_X, train_y)\n",
    "predictions = knn_classif.predict(test_X)\n",
    "\n",
    "print(confusion_matrix(test_y, np.asarray(predictions)).transpose())\n",
    "print(accuracy_score(test_y, np.asarray(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 55]\n",
      " [63 86]]\n",
      "0.531746031746\n"
     ]
    }
   ],
   "source": [
    "knn_classif = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_classif.fit(train_X, train_y)\n",
    "predictions = knn_classif.predict(test_X)\n",
    "\n",
    "print(confusion_matrix(test_y, np.asarray(predictions)).transpose())\n",
    "print(accuracy_score(test_y, np.asarray(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Application to Caravan Insurance Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5822, 86)\n",
      "No     5474\n",
      "Yes     348\n",
      "Name: Purchase, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "caravan_df = pd.read_csv('../data/Caravan.csv')\n",
    "caravan_df.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "print(caravan_df.shape)\n",
    "print(caravan_df['Purchase'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>MRELGE</th>\n",
       "      <th>...</th>\n",
       "      <th>ALEVEN</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "      <td>5.822000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.238000e-17</td>\n",
       "      <td>-1.983222e-16</td>\n",
       "      <td>-1.482840e-16</td>\n",
       "      <td>2.096113e-16</td>\n",
       "      <td>-5.675067e-17</td>\n",
       "      <td>-6.285289e-17</td>\n",
       "      <td>8.787200e-17</td>\n",
       "      <td>-3.478267e-17</td>\n",
       "      <td>1.122809e-16</td>\n",
       "      <td>-1.696418e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006867e-17</td>\n",
       "      <td>-6.102222e-18</td>\n",
       "      <td>3.539289e-17</td>\n",
       "      <td>-9.763555e-18</td>\n",
       "      <td>-1.232649e-16</td>\n",
       "      <td>5.492000e-18</td>\n",
       "      <td>3.295200e-17</td>\n",
       "      <td>1.952711e-17</td>\n",
       "      <td>2.440889e-18</td>\n",
       "      <td>-5.186889e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.810063e+00</td>\n",
       "      <td>-2.725565e-01</td>\n",
       "      <td>-2.125514e+00</td>\n",
       "      <td>-2.444473e+00</td>\n",
       "      <td>-1.670990e+00</td>\n",
       "      <td>-6.942510e-01</td>\n",
       "      <td>-2.696595e+00</td>\n",
       "      <td>-1.051503e+00</td>\n",
       "      <td>-2.039564e+00</td>\n",
       "      <td>-3.238282e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.028925e-01</td>\n",
       "      <td>-7.315883e-02</td>\n",
       "      <td>-8.104764e-02</td>\n",
       "      <td>-5.991487e-02</td>\n",
       "      <td>-1.014271e+00</td>\n",
       "      <td>-2.270383e-02</td>\n",
       "      <td>-7.364394e-02</td>\n",
       "      <td>-1.506075e-01</td>\n",
       "      <td>-8.734022e-02</td>\n",
       "      <td>-1.188063e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.109495e+00</td>\n",
       "      <td>-2.725565e-01</td>\n",
       "      <td>-8.594262e-01</td>\n",
       "      <td>-1.216859e+00</td>\n",
       "      <td>-9.708962e-01</td>\n",
       "      <td>-6.942510e-01</td>\n",
       "      <td>-3.653787e-01</td>\n",
       "      <td>-1.051503e+00</td>\n",
       "      <td>-7.877226e-01</td>\n",
       "      <td>-6.197711e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.028925e-01</td>\n",
       "      <td>-7.315883e-02</td>\n",
       "      <td>-8.104764e-02</td>\n",
       "      <td>-5.991487e-02</td>\n",
       "      <td>-1.014271e+00</td>\n",
       "      <td>-2.270383e-02</td>\n",
       "      <td>-7.364394e-02</td>\n",
       "      <td>-1.506075e-01</td>\n",
       "      <td>-8.734022e-02</td>\n",
       "      <td>-1.188063e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.473248e-01</td>\n",
       "      <td>-2.725565e-01</td>\n",
       "      <td>4.066617e-01</td>\n",
       "      <td>1.075374e-02</td>\n",
       "      <td>4.292915e-01</td>\n",
       "      <td>-6.942510e-01</td>\n",
       "      <td>2.174254e-01</td>\n",
       "      <td>-6.870474e-02</td>\n",
       "      <td>-1.618019e-01</td>\n",
       "      <td>-9.606902e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.028925e-01</td>\n",
       "      <td>-7.315883e-02</td>\n",
       "      <td>-8.104764e-02</td>\n",
       "      <td>-5.991487e-02</td>\n",
       "      <td>7.649050e-01</td>\n",
       "      <td>-2.270383e-02</td>\n",
       "      <td>-7.364394e-02</td>\n",
       "      <td>-1.506075e-01</td>\n",
       "      <td>-8.734022e-02</td>\n",
       "      <td>-1.188063e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.365297e-01</td>\n",
       "      <td>-2.725565e-01</td>\n",
       "      <td>4.066617e-01</td>\n",
       "      <td>1.075374e-02</td>\n",
       "      <td>7.793384e-01</td>\n",
       "      <td>3.025256e-01</td>\n",
       "      <td>8.002294e-01</td>\n",
       "      <td>9.140938e-01</td>\n",
       "      <td>4.641188e-01</td>\n",
       "      <td>4.276331e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.028925e-01</td>\n",
       "      <td>-7.315883e-02</td>\n",
       "      <td>-8.104764e-02</td>\n",
       "      <td>-5.991487e-02</td>\n",
       "      <td>7.649050e-01</td>\n",
       "      <td>-2.270383e-02</td>\n",
       "      <td>-7.364394e-02</td>\n",
       "      <td>-1.506075e-01</td>\n",
       "      <td>-8.734022e-02</td>\n",
       "      <td>-1.188063e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.303575e+00</td>\n",
       "      <td>2.190356e+01</td>\n",
       "      <td>2.938838e+00</td>\n",
       "      <td>3.693593e+00</td>\n",
       "      <td>1.479432e+00</td>\n",
       "      <td>8.276739e+00</td>\n",
       "      <td>2.548642e+00</td>\n",
       "      <td>3.862489e+00</td>\n",
       "      <td>3.593722e+00</td>\n",
       "      <td>1.475037e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.098527e+01</td>\n",
       "      <td>1.366654e+01</td>\n",
       "      <td>1.233630e+01</td>\n",
       "      <td>2.577893e+01</td>\n",
       "      <td>1.143996e+01</td>\n",
       "      <td>4.403786e+01</td>\n",
       "      <td>2.442664e+01</td>\n",
       "      <td>1.406837e+01</td>\n",
       "      <td>2.202113e+01</td>\n",
       "      <td>1.654842e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MOSTYPE      MAANTHUI       MGEMOMV      MGEMLEEF      MOSHOOFD  \\\n",
       "count  5.822000e+03  5.822000e+03  5.822000e+03  5.822000e+03  5.822000e+03   \n",
       "mean  -8.238000e-17 -1.983222e-16 -1.482840e-16  2.096113e-16 -5.675067e-17   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.810063e+00 -2.725565e-01 -2.125514e+00 -2.444473e+00 -1.670990e+00   \n",
       "25%   -1.109495e+00 -2.725565e-01 -8.594262e-01 -1.216859e+00 -9.708962e-01   \n",
       "50%    4.473248e-01 -2.725565e-01  4.066617e-01  1.075374e-02  4.292915e-01   \n",
       "75%    8.365297e-01 -2.725565e-01  4.066617e-01  1.075374e-02  7.793384e-01   \n",
       "max    1.303575e+00  2.190356e+01  2.938838e+00  3.693593e+00  1.479432e+00   \n",
       "\n",
       "             MGODRK        MGODPR        MGODOV        MGODGE        MRELGE  \\\n",
       "count  5.822000e+03  5.822000e+03  5.822000e+03  5.822000e+03  5.822000e+03   \n",
       "mean  -6.285289e-17  8.787200e-17 -3.478267e-17  1.122809e-16 -1.696418e-16   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -6.942510e-01 -2.696595e+00 -1.051503e+00 -2.039564e+00 -3.238282e+00   \n",
       "25%   -6.942510e-01 -3.653787e-01 -1.051503e+00 -7.877226e-01 -6.197711e-01   \n",
       "50%   -6.942510e-01  2.174254e-01 -6.870474e-02 -1.618019e-01 -9.606902e-02   \n",
       "75%    3.025256e-01  8.002294e-01  9.140938e-01  4.641188e-01  4.276331e-01   \n",
       "max    8.276739e+00  2.548642e+00  3.862489e+00  3.593722e+00  1.475037e+00   \n",
       "\n",
       "           ...             ALEVEN      APERSONG       AGEZONG       AWAOREG  \\\n",
       "count      ...       5.822000e+03  5.822000e+03  5.822000e+03  5.822000e+03   \n",
       "mean       ...       1.006867e-17 -6.102222e-18  3.539289e-17 -9.763555e-18   \n",
       "std        ...       1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min        ...      -2.028925e-01 -7.315883e-02 -8.104764e-02 -5.991487e-02   \n",
       "25%        ...      -2.028925e-01 -7.315883e-02 -8.104764e-02 -5.991487e-02   \n",
       "50%        ...      -2.028925e-01 -7.315883e-02 -8.104764e-02 -5.991487e-02   \n",
       "75%        ...      -2.028925e-01 -7.315883e-02 -8.104764e-02 -5.991487e-02   \n",
       "max        ...       2.098527e+01  1.366654e+01  1.233630e+01  2.577893e+01   \n",
       "\n",
       "             ABRAND       AZEILPL      APLEZIER        AFIETS       AINBOED  \\\n",
       "count  5.822000e+03  5.822000e+03  5.822000e+03  5.822000e+03  5.822000e+03   \n",
       "mean  -1.232649e-16  5.492000e-18  3.295200e-17  1.952711e-17  2.440889e-18   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.014271e+00 -2.270383e-02 -7.364394e-02 -1.506075e-01 -8.734022e-02   \n",
       "25%   -1.014271e+00 -2.270383e-02 -7.364394e-02 -1.506075e-01 -8.734022e-02   \n",
       "50%    7.649050e-01 -2.270383e-02 -7.364394e-02 -1.506075e-01 -8.734022e-02   \n",
       "75%    7.649050e-01 -2.270383e-02 -7.364394e-02 -1.506075e-01 -8.734022e-02   \n",
       "max    1.143996e+01  4.403786e+01  2.442664e+01  1.406837e+01  2.202113e+01   \n",
       "\n",
       "           ABYSTAND  \n",
       "count  5.822000e+03  \n",
       "mean  -5.186889e-18  \n",
       "std    1.000000e+00  \n",
       "min   -1.188063e-01  \n",
       "25%   -1.188063e-01  \n",
       "50%   -1.188063e-01  \n",
       "75%   -1.188063e-01  \n",
       "max    1.654842e+01  \n",
       "\n",
       "[8 rows x 85 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "caravan_nums_df = caravan_df.drop('Purchase', axis=1)\n",
    "responses = np.ravel(caravan_df['Purchase'])\n",
    "\n",
    "caravan_nums_df = (caravan_nums_df - caravan_nums_df.mean())/caravan_nums_df.std()\n",
    "caravan_nums_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.110949813355\n"
     ]
    }
   ],
   "source": [
    "train_X = caravan_nums_df[:1000]\n",
    "train_y = responses[:1000]\n",
    "test_X =caravan_nums_df[1000:]\n",
    "test_y = responses[1000:]\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_model.fit(train_X, train_y)\n",
    "predicted = np.ravel(knn_model.predict(test_X))\n",
    "\n",
    "print(1 - accuracy_score(test_y, np.asarray(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0746578183326\n",
      "[[4437   96]\n",
      " [ 264   25]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.94      0.98      0.96      4533\n",
      "        Yes       0.21      0.09      0.12       289\n",
      "\n",
      "avg / total       0.90      0.93      0.91      4822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(train_X, train_y)\n",
    "predicted = np.ravel(knn_model.predict(test_X))\n",
    "\n",
    "print(1 - accuracy_score(test_y, np.asarray(predicted)))\n",
    "print(confusion_matrix(test_y, np.asarray(predicted).transpose()))\n",
    "print(classification_report(test_y, np.asarray(predicted).transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0634591455827\n",
      "[[4506   27]\n",
      " [ 279   10]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.94      0.99      0.97      4533\n",
      "        Yes       0.27      0.03      0.06       289\n",
      "\n",
      "avg / total       0.90      0.94      0.91      4822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(train_X, train_y)\n",
    "predicted = knn_model.predict(test_X)\n",
    "\n",
    "print(1 - accuracy_score(test_y, np.asarray(predicted)))\n",
    "print(confusion_matrix(test_y, np.asarray(predicted).transpose()))\n",
    "print(classification_report(test_y, np.asarray(predicted).transpose()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
